{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convolutional_network import *\n",
    "from optimizer import SGD\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 32, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "x = df.drop(columns='label').to_numpy()\n",
    "x = x/255.0\n",
    "x = x.reshape(x.shape[0], 28, 28, 1)\n",
    "x = np.pad(x, pad_width=((0, 0), (2, 2), (2, 2), (0, 0)), mode='constant', constant_values=0)\n",
    "random_indices = np.random.choice(x.shape[0], size=num_sample, replace=False)\n",
    "x = x[random_indices]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_coding(y):\n",
    "    y_new = []\n",
    "    for i in y.values:\n",
    "        y_n = [0] * 10\n",
    "        y_n[i] = 1\n",
    "        y_new.append(y_n)\n",
    "    y_new = np.array(y_new)\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label']\n",
    "y = one_hot_coding(y)\n",
    "y = y[random_indices]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5 = Convolutional_Neural_Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LeNet-5 Architecture**\n",
    "\n",
    "Input -> Convo(5, 5) -> Subsampling -> Convo(5, 5) ->Subsampling -> Convo(5, 5) -> Flatten -> Dense -> Dense (Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input_shape = (32, 32, 1)**\n",
    "\n",
    "**Layer 0 : Convolutional Layer** \n",
    "- input shape         = (32, 32, 1)\n",
    "- number of filters   = 6\n",
    "- kernel size         = (5, 5)\n",
    "- activation function = tanh\n",
    "- stride              = 1\n",
    "- padding             = valid\\\n",
    "***-> output shape    = (28, 28, 6)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genearate filters\n"
     ]
    }
   ],
   "source": [
    "lenet5.add(Layers.Convo(num_filter=6, kernel_size=(5, 5), activation='tanh', stride=1, padding='valid', input_shape=(1, 32, 32, 1))) # ! layer 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 1 : Subsampling Layer (Average Pooling)** \n",
    "- input shape = (28, 28, 6)\n",
    "- kernel size = (2, 2)\n",
    "- stride = 2\n",
    "- padding = valid\\\n",
    "***-> output shape = (14, 14, 6)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5.add(Layers.AvgPool(kernel_size=(2, 2), stride=2, padding='valid')) # ! layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 2 : Convolutional Layer**\n",
    "- input shape         = (14, 14, 6)\n",
    "- number of filters   = 16\n",
    "- kernel size         = (5, 5)\n",
    "- activation function = tanh\n",
    "- stride              = 1\n",
    "- padding             = valid\\\n",
    "***-> output shape    = (10, 10, 16)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genearate filters\n"
     ]
    }
   ],
   "source": [
    "lenet5.add(Layers.Convo(num_filter=16, kernel_size=(5, 5), activation='tanh', stride=1, padding='valid', input_shape=(1, 14, 14, 6))) # ! layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 3 : Subsampling Layer (Average Pooling)** \n",
    "- input shape = (10, 10, 16)\n",
    "- kernel size = (2, 2)\n",
    "- stride = 2\n",
    "- padding = valid\\\n",
    "***-> output shape = (5, 5, 16)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5.add(Layers.AvgPool(kernel_size=(2, 2), stride=2, padding='valid')) # ! layer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 4 : Convolutional Layer**\n",
    "- input shape         = (5, 5, 16)\n",
    "- number of filters   = 120\n",
    "- kernel size         = (5, 5)\n",
    "- activation function = tanh\n",
    "- stride              = 1\n",
    "- padding             = valid\\\n",
    "***-> output shape    = (1, 1, 120)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genearate filters\n"
     ]
    }
   ],
   "source": [
    "lenet5.add(Layers.Convo(num_filter=120, kernel_size=(5, 5), activation='tanh', stride=1, padding='valid', input_shape=(1, 5, 5, 16))) # ! layer 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 5 : Flatten Layer**\n",
    "- input shape         = (1, 1, 120)\\\n",
    "***-> output shape    = (120, 1)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5.add(Layers.Flatten()) # ! layer 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 6 : Dense Layer**\n",
    "- input shape         = (120, 1)\n",
    "- dimension           = 84\n",
    "- activation function = tanh\n",
    "- train bias          = True\\\n",
    "***-> output shape    = (84, 1)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate weights\n"
     ]
    }
   ],
   "source": [
    "lenet5.add(Layers.Dense(dim=(120, 84), activation='tanh', train_bias=True, xavier_uniform=True)) # ! layer 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 7 : Dense Layer (Output)**\n",
    "- input shape         = (84, 1)\n",
    "- dimension           = 84\n",
    "- activation function = Softmax\n",
    "- train bias          = True\\\n",
    "***-> output shape    = (10, 1)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate weights\n"
     ]
    }
   ],
   "source": [
    "lenet5.add(Layers.Dense(dim=(84, 10), activation='softmax', train_bias=True, xavier_uniform=True)) # ! layer 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Total number of layers : 8_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, x_test, y_test, learning_rate = 0.01, epochs = 100, batch_size = 32):\n",
    "    from tqdm import tqdm\n",
    "    optim = SGD(model=lenet5, learning_rate=learning_rate)\n",
    "    accuracy_points = []    \n",
    "    loss_points = []\n",
    "    for epoch in tqdm(range(epochs), desc='Epochs'):\n",
    "        random_index = np.random.choice(x_train.shape[0], size=batch_size, replace=False)\n",
    "        for i in random_index:\n",
    "            xi = x_train[i, :].reshape(1, 32, 32, 1)\n",
    "            yi = y_train[i, :].reshape(10, 1)\n",
    "            \n",
    "            # ! foward pass\n",
    "            lenet5.forward_pass(xi)\n",
    "            # ! backward pass\n",
    "            lenet5.backpropagation(yi)\n",
    "            # ! update parameters\n",
    "            optim.step()\n",
    "            \n",
    "            \n",
    "        # if epoch % 10 == 0:\n",
    "        #     y_pred = lenet5.predict(x_train)\n",
    "        #     accuracy_point = lenet5.accuracy(y_train, y_pred)\n",
    "        #     accuracy_points.append(accuracy_point * 100)\n",
    "        #     loss_point = lenet5.cross_entropy_loss(y_train, y_pred)\n",
    "        #     loss_points.append(loss_point)\n",
    "        \n",
    "    \n",
    "    print('-----------------------------------------------------------')\n",
    "    y_pred = lenet5.predict(x_train)\n",
    "    accuracy = lenet5.accuracy(y_train, y_pred)\n",
    "    print(\"\\ntrain accuracy :\", accuracy)\n",
    "    loss = lenet5.cross_entropy_loss(y_train, y_pred)\n",
    "    print(\"train cross-entropy loss :\", loss)\n",
    "    print('-----------------------------------------------------------')\n",
    "    y_pred_test = lenet5.predict(x_test)\n",
    "    accuracy_test = lenet5.accuracy(y_test, y_pred_test)\n",
    "    print(\"\\ntest accuracy :\", accuracy_test)\n",
    "    loss_test = lenet5.cross_entropy_loss(y_test, y_pred_test)\n",
    "    print(\"test cross-entropy loss :\", loss_test)\n",
    "    print('-----------------------------------------------------------')\n",
    "    \n",
    "    return accuracy_points, loss_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 250/250 [29:11<00:00,  7.01s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "\n",
      "train accuracy : 0.9366666666666666\n",
      "train cross-entropy loss : 8.29768173238267\n",
      "-----------------------------------------------------------\n",
      "\n",
      "test accuracy : 0.83\n",
      "test cross-entropy loss : 6.444873591553233\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch = 250\n",
    "acc, loss = train(x_train, y_train, x_test, y_test, learning_rate=0.05, epochs=epoch, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(epoch, acc, loss):\n",
    "    plt.plot([i for i in range(0, epoch, 10)], acc)\n",
    "    plt.plot([i for i in range(0, epoch, 10)], loss)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy/Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_acc_loss(epoch, acc, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
